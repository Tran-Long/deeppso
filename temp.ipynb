{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46b38148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.nn as gnn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02e7fa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(2, 3)\n",
    "b = torch.randn(2, 3)\n",
    "\n",
    "n = nn.Linear(3, 3)\n",
    "out_a = n(a)\n",
    "out_b = n(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e01e727",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "ðŸ’¡ Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as L\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=100,\n",
    "    accelerator=\"auto\",\n",
    "    devices=\"auto\",\n",
    "    num_sanity_val_steps=0,\n",
    "    log_every_n_steps=10,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df72037f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\n",
    "    \"a\": [1, 2, 3],\n",
    "    \"b\": [4, 5, 6],\n",
    "}\n",
    "d_plus1 = {\n",
    "    k: [x + 1 for x in v] for k, v in d.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b694e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5, 3])\n",
      "torch.Size([5, 5, 3])\n",
      "torch.Size([5, 5, 3])\n"
     ]
    }
   ],
   "source": [
    "from torch.distributions import Normal\n",
    "mean = torch.zeros(5, 5, 3)\n",
    "std = torch.ones(5, 5, 3)\n",
    "dist = Normal(mean, std)\n",
    "samples = dist.sample()\n",
    "print(samples.shape)\n",
    "print(dist.log_prob(samples).shape)\n",
    "print(dist.entropy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0788043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Categorical\n",
    "\n",
    "t = torch.tensor([[0.1, float('-inf'), 0.7], [2.0, 1.0, 0.1]])\n",
    "d = Categorical(logits=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "776ee463",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected parameter probs (Tensor of shape (3,)) of distribution Categorical(probs: torch.Size([3])) to satisfy the constraint Simplex(), but found invalid values:\ntensor([nan, nan, nan])",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m t = torch.tensor([\u001b[32m0.0\u001b[39m, \u001b[32m0.0\u001b[39m, \u001b[32m0.0\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m d = \u001b[43mCategorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/distributions/categorical.py:72\u001b[39m, in \u001b[36mCategorical.__init__\u001b[39m\u001b[34m(self, probs, logits, validate_args)\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;28mself\u001b[39m._num_events = \u001b[38;5;28mself\u001b[39m._param.size()[-\u001b[32m1\u001b[39m]\n\u001b[32m     69\u001b[39m batch_shape = (\n\u001b[32m     70\u001b[39m     \u001b[38;5;28mself\u001b[39m._param.size()[:-\u001b[32m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._param.ndimension() > \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m torch.Size()\n\u001b[32m     71\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/distributions/distribution.py:72\u001b[39m, in \u001b[36mDistribution.__init__\u001b[39m\u001b[34m(self, batch_shape, event_shape, validate_args)\u001b[39m\n\u001b[32m     70\u001b[39m         valid = constraint.check(value)\n\u001b[32m     71\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch._is_all_true(valid):\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     73\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     74\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value.shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     75\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mof distribution \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     76\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mto satisfy the constraint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(constraint)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     77\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     78\u001b[39m             )\n\u001b[32m     79\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n",
      "\u001b[31mValueError\u001b[39m: Expected parameter probs (Tensor of shape (3,)) of distribution Categorical(probs: torch.Size([3])) to satisfy the constraint Simplex(), but found invalid values:\ntensor([nan, nan, nan])"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([0.0, 0.0, 0.0])\n",
    "d = Categorical(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32beb1d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape mismatch: value tensor of shape [3, 15] cannot be broadcast to indexing result of shape [15, 5]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m mat = torch.zeros((n_particles, n_cities, n_cities))\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mmat\u001b[49m\u001b[43m[\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m = edge_values\n",
      "\u001b[31mRuntimeError\u001b[39m: shape mismatch: value tensor of shape [3, 15] cannot be broadcast to indexing result of shape [15, 5]"
     ]
    }
   ],
   "source": [
    "mat = torch.zeros((n_particles, n_cities, n_cities))\n",
    "mat[edge_index[0], edge_index[1]] = edge_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd9c41f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3569, 0.4387, 0.8685, 0.9301, 0.3460, 0.7346, 0.7125, 0.7116, 0.0034,\n",
       "         0.8694, 0.1189, 0.6987, 0.4217, 0.2760, 0.2783],\n",
       "        [0.1926, 0.8375, 0.0232, 0.6832, 0.7921, 0.0502, 0.7298, 0.2785, 0.8785,\n",
       "         0.4541, 0.8964, 0.0214, 0.7403, 0.7855, 0.6148],\n",
       "        [0.5817, 0.5351, 0.1427, 0.6011, 0.6688, 0.9171, 0.1967, 0.2369, 0.4065,\n",
       "         0.1424, 0.7792, 0.4304, 0.4078, 0.5154, 0.2953]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d673521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.3569, 0.4387, 0.8685, 0.0000],\n",
       "         [0.9301, 0.0000, 0.3460, 0.0000, 0.7346],\n",
       "         [0.7125, 0.7116, 0.0000, 0.0000, 0.0034],\n",
       "         [0.8694, 0.0000, 0.1189, 0.0000, 0.6987],\n",
       "         [0.0000, 0.4217, 0.2760, 0.2783, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.1926, 0.8375, 0.0232, 0.0000],\n",
       "         [0.6832, 0.0000, 0.7921, 0.0000, 0.0502],\n",
       "         [0.7298, 0.2785, 0.0000, 0.0000, 0.8785],\n",
       "         [0.4541, 0.0000, 0.8964, 0.0000, 0.0214],\n",
       "         [0.0000, 0.7403, 0.7855, 0.6148, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.5817, 0.5351, 0.1427, 0.0000],\n",
       "         [0.6011, 0.0000, 0.6688, 0.0000, 0.9171],\n",
       "         [0.1967, 0.2369, 0.0000, 0.0000, 0.4065],\n",
       "         [0.1424, 0.0000, 0.7792, 0.0000, 0.4304],\n",
       "         [0.0000, 0.4078, 0.5154, 0.2953, 0.0000]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761ed1be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "129e7769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.randn(4, 16)  # Example input tensor with shape (4, 16)\n",
    "o = F.gumbel_softmax(t, tau=1, hard=True)\n",
    "print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecf7b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_tour_differentiable(particle_X, temperature=1.0):\n",
    "    num_cities = particle_X.shape\n",
    "    tour = []\n",
    "    mask = torch.zeros(num_cities)\n",
    "    \n",
    "    for _ in range(num_cities):\n",
    "        # Apply mask to priorities\n",
    "        masked_logits = particle_X.masked_fill(mask.bool(), float('-inf'))\n",
    "        \n",
    "        # Gumbel-Softmax for differentiable sampling\n",
    "        # Use hard=True for a one-hot vector in forward, softmax in backward\n",
    "        prob_vec = torch.nn.functional.gumbel_softmax(masked_logits, tau=temperature, hard=True)\n",
    "        \n",
    "        city_idx = prob_vec.argmax()\n",
    "        tour.append(city_idx)\n",
    "        mask[city_idx] = 1\n",
    "        \n",
    "    return tour # Used for cost evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 32])\n"
     ]
    }
   ],
   "source": [
    "conv = gnn.GCNConv(16, 32)\n",
    "i = torch.randn(4, 16)\n",
    "edge_index = torch.tensor([[0, 1, 2, 3, 0, 2],\n",
    "                           [1, 0, 3, 2, 2, 0]], dtype=torch.long)\n",
    "o = conv(i, edge_index)\n",
    "print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e4a3884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 16, 1])\n"
     ]
    }
   ],
   "source": [
    "o = nn.AdaptiveAvgPool1d(1)(torch.randn(4, 16, 10))  # IGNORE\n",
    "print(o.shape)  # IGNORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09d5417f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3, 4, 1, 4, 0, 2, 3, 0, 3, 4, 1, 2, 0, 4, 1, 1, 2, 0, 3],\n",
       "        [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnn.knn_graph(torch.randn(5, 3), k=6)  # IGNORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3f3cc4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4],\n",
       "        [1, 2, 3, 4, 0, 2, 3, 4, 0, 1, 3, 4, 0, 1, 2, 4, 0, 1, 2, 3]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_cities = 5\n",
    "if False:\n",
    "    row = torch.arange(n_cities).unsqueeze(1).repeat(1, n_cities).view(-1)\n",
    "    col = torch.arange(n_cities).unsqueeze(0).repeat(n_cities, 1).view(-1)\n",
    "else:\n",
    "    row = torch.arange(n_cities).unsqueeze(1).repeat(1, n_cities - 1).view(-1)\n",
    "    col = torch.cat([torch.cat([torch.arange(i), torch.arange(i + 1, n_cities)]) for i in range(n_cities)], dim=0)\n",
    "edge_index = torch.stack([row, col], dim=0)\n",
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac5af0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 4, 2, 1, 4, 2, 0, 3, 0, 4, 3, 1, 0, 4, 2, 1, 3, 0, 2, 1],\n",
       "        [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnn.knn_graph(torch.randn(n_cities, 3), k=n_cities, loop=False)  # IGNORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b34aa141",
   "metadata": {},
   "outputs": [],
   "source": [
    "from problems import ProblemDataModule, TSPProblem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47aa291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = ProblemDataModule(\n",
    "    problem_cls=TSPProblem,\n",
    "    step_per_epoch=128,\n",
    "    n_cities=50,\n",
    "    k_sparse=10,\n",
    "    n_dims=2,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e048510f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 0, 1, 4, 2],\n",
       "        [4, 0, 3, 2, 1],\n",
       "        [3, 1, 0, 2, 4],\n",
       "        [0, 3, 1, 4, 2],\n",
       "        [4, 1, 3, 0, 2],\n",
       "        [3, 2, 0, 1, 4],\n",
       "        [4, 3, 2, 0, 1],\n",
       "        [2, 4, 0, 1, 3],\n",
       "        [4, 1, 0, 3, 2],\n",
       "        [2, 3, 4, 0, 1],\n",
       "        [3, 0, 4, 1, 2],\n",
       "        [4, 2, 1, 3, 0],\n",
       "        [2, 1, 3, 4, 0],\n",
       "        [0, 3, 2, 4, 1],\n",
       "        [0, 3, 4, 1, 2],\n",
       "        [1, 3, 0, 2, 4],\n",
       "        [1, 4, 0, 3, 2],\n",
       "        [4, 1, 2, 3, 0],\n",
       "        [0, 3, 1, 4, 2],\n",
       "        [3, 0, 1, 4, 2]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "n_particles = 20\n",
    "n_starts = 5\n",
    "n_cities = 5\n",
    "\n",
    "starts = []\n",
    "for _ in range(n_particles):\n",
    "    starts.append(torch.randperm(n_cities)[:n_starts])\n",
    "torch.stack(starts, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91214175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 3, 2, 3, 3, 2, 2, 2, 2, 1, 4, 4, 1, 1, 4, 3, 2, 1, 0, 3]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorized alternative to generate starts (no Python loop)\n",
    "starts = torch.rand(n_particles, n_cities).argsort(dim=1)[:, :1]\n",
    "starts.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bba12128",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = data_module.train_dataloader()\n",
    "cnt = 0\n",
    "for problem in train_dataloader:\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "043335ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[50, 2], edge_index=[2, 500], edge_attr=[500, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem.pyg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "443b6558",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem.pyg_data = problem.pyg_data.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48c61e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from copy import deepcopy\n",
    "import torch_geometric.nn as gnn\n",
    "\n",
    "# GNN for edge embeddings\n",
    "class EmbNet(nn.Module):\n",
    "    def __init__(self, depth=12, feats=2, units=32, act_fn='silu', agg_fn='mean'): # TODO feats=1\n",
    "        super().__init__()\n",
    "        self.depth = depth\n",
    "        self.feats = feats\n",
    "        self.units = units\n",
    "        self.act_fn = getattr(F, act_fn)\n",
    "        self.agg_fn = getattr(gnn, f'global_{agg_fn}_pool')\n",
    "        self.v_lin0 = nn.Linear(self.feats, self.units)\n",
    "        self.v_lins1 = nn.ModuleList([nn.Linear(self.units, self.units) for i in range(self.depth)])\n",
    "        self.v_lins2 = nn.ModuleList([nn.Linear(self.units, self.units) for i in range(self.depth)])\n",
    "        self.v_lins3 = nn.ModuleList([nn.Linear(self.units, self.units) for i in range(self.depth)])\n",
    "        self.v_lins4 = nn.ModuleList([nn.Linear(self.units, self.units) for i in range(self.depth)])\n",
    "        self.v_bns = nn.ModuleList([gnn.BatchNorm(self.units) for i in range(self.depth)])\n",
    "        self.e_lin0 = nn.Linear(1, self.units)\n",
    "        self.e_lins0 = nn.ModuleList([nn.Linear(self.units, self.units) for i in range(self.depth)])\n",
    "        self.e_bns = nn.ModuleList([gnn.BatchNorm(self.units) for i in range(self.depth)])\n",
    "    def reset_parameters(self):\n",
    "        raise NotImplementedError\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = x\n",
    "        w = edge_attr\n",
    "        x = self.v_lin0(x)\n",
    "        x = self.act_fn(x)\n",
    "        w = self.e_lin0(w)\n",
    "        w = self.act_fn(w)\n",
    "        for i in range(self.depth):\n",
    "            x0 = x\n",
    "            x1 = self.v_lins1[i](x0)\n",
    "            x2 = self.v_lins2[i](x0)\n",
    "            x3 = self.v_lins3[i](x0)\n",
    "            x4 = self.v_lins4[i](x0)\n",
    "            w0 = w\n",
    "            w1 = self.e_lins0[i](w0)\n",
    "            w2 = torch.sigmoid(w0)\n",
    "            x = x0 + self.act_fn(self.v_bns[i](x1 + self.agg_fn(w2 * x2[edge_index[1]], edge_index[0])))\n",
    "            w = w0 + self.act_fn(self.e_bns[i](w1 + x3[edge_index[0]] + x4[edge_index[1]]))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fb72af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 5, 32])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_geometric.nn as gnn\n",
    "import torch\n",
    "\n",
    "gcn_net = gnn.GCN(in_channels=2, hidden_channels=16, num_layers=2, out_channels=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5efb48f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 5, 32])\n",
      "torch.Size([5, 32])\n",
      "torch.Size([5, 32])\n",
      "tensor(0., grad_fn=<MaxBackward1>)\n",
      "tensor(0., grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(6, 5, 2)\n",
    "x1 = x[0]\n",
    "x4 = x[4]\n",
    "# Define a full edge index for a graph with 5 nodes\n",
    "edge_index = torch.tensor([\n",
    "    [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4],\n",
    "    [1, 2, 3, 4, 0, 2, 3, 4, 0, 1, 3, 4, 0, 1, 2, 4, 0, 1, 2, 3]\n",
    "], dtype=torch.long)\n",
    "out = gcn_net(x, edge_index)\n",
    "print(out.shape)\n",
    "out1 = gcn_net(x1, edge_index)\n",
    "out4 = gcn_net(x4, edge_index)\n",
    "print(out1.shape)\n",
    "print(out4.shape)\n",
    "print((out[0] - out1).abs().max())\n",
    "print((out[4] - out4).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad230a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 0, 1, 2, 3,\n",
       "         4, 5],\n",
       "        [1, 2, 3, 4, 0, 2, 3, 4, 0, 1, 3, 4, 0, 1, 2, 4, 0, 1, 2, 3, 0, 1, 2, 3,\n",
       "         4, 5]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.utils import add_self_loops, degree\n",
    "\n",
    "edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a308ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 32])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = EmbNet(feats=2)\n",
    "import torch\n",
    "\n",
    "x = torch.randn(5, 2)\n",
    "edge_index = torch.tensor([[0, 1, 2, 3, 4, 0],\n",
    "                           [1, 0, 3, 2, 0, 4]], dtype=torch.long)\n",
    "\n",
    "x, edge_index, edge_attr = problem.pyg_data.x, problem.pyg_data.edge_index, problem.pyg_data.edge_attr\n",
    "\n",
    "out = net(x, edge_index, edge_attr)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35054ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 50])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c9d74f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3209, 0.2086, 0.4127, 0.1192, 0.5564])\n",
      "tensor(0) tensor(-1.6239)\n",
      "tensor(4) tensor(-1.3884)\n",
      "tensor(4) tensor(-1.3884)\n",
      "tensor(4) tensor(-1.3884)\n",
      "tensor(0) tensor(-1.6239)\n",
      "tensor(0) tensor(-1.6239)\n",
      "tensor(2) tensor(-1.5321)\n",
      "tensor(0) tensor(-1.6239)\n",
      "tensor(4) tensor(-1.3884)\n",
      "tensor(4) tensor(-1.3884)\n"
     ]
    }
   ],
   "source": [
    "import torch.distributions as dst\n",
    "import torch\n",
    "\n",
    "t = torch.rand(5)\n",
    "print(t)\n",
    "\n",
    "dist = dst.Categorical(logits=t)\n",
    "for _ in range(10):\n",
    "    sample = dist.sample()\n",
    "    print(sample, dist.log_prob(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eeaa837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3874, 0.5897, 0.0379, 0.4437, 0.1253])\n",
      "tensor([1.9370, 2.9487, 0.1896, 2.2185, 0.6266])\n"
     ]
    }
   ],
   "source": [
    "import torch.distributions as dst\n",
    "import torch\n",
    "t = torch.rand(5)\n",
    "print(t)\n",
    "t5 = t*5\n",
    "print(t5)\n",
    "dt = dst.Categorical(logits=t)\n",
    "dt5 = dst.Categorical(logits=t5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adfc5078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(18) tensor(-2.9957)\n",
      "tensor(1) tensor(-2.9957)\n",
      "tensor(0) tensor(-2.9957)\n",
      "tensor(19) tensor(-2.9957)\n",
      "tensor(16) tensor(-2.9957)\n",
      "tensor(19) tensor(-2.9957)\n",
      "tensor(13) tensor(-2.9957)\n",
      "tensor(0) tensor(-2.9957)\n",
      "tensor(13) tensor(-2.9957)\n",
      "tensor(8) tensor(-2.9957)\n"
     ]
    }
   ],
   "source": [
    "n = 20\n",
    "d = dst.Categorical(probs=torch.ones(n)/n)\n",
    "for i in range(10):\n",
    "    sample = d.sample()\n",
    "    print(sample, d.log_prob(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30a8822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_solution(tensor: torch.Tensor) -> torch.Tensor:\n",
    "    n = tensor.size(0)\n",
    "    seq = []\n",
    "    for _ in range(n):\n",
    "        tensor = tensor / tensor.sum()\n",
    "        d = dst.Categorical(probs=tensor)\n",
    "        sample = d.sample()\n",
    "        seq.append(sample.item())\n",
    "        # Mask the selected city\n",
    "        tensor[sample] = 0.0\n",
    "    return torch.tensor(seq, device=tensor.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "01a2e3e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = torch.rand(10, 5)\n",
    "d = dst.Categorical(probs=mat)\n",
    "d0 = d.sample()\n",
    "d1 = d.sample()\n",
    "\n",
    "torch.stack([d0, d1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d850f4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 4, 0, 3, 2])\n",
      "---\n",
      "tensor([0, 4, 2, 3, 1])\n",
      "---\n",
      "tensor([0, 4, 3, 1, 2])\n",
      "---\n",
      "tensor([4, 1, 2, 0, 3])\n",
      "---\n",
      "tensor([2, 3, 4, 0, 1])\n",
      "---\n",
      "tensor([0, 4, 1, 2, 3])\n",
      "---\n",
      "tensor([4, 3, 2, 1, 0])\n",
      "---\n",
      "tensor([3, 0, 2, 4, 1])\n",
      "---\n",
      "tensor([4, 0, 2, 1, 3])\n",
      "---\n",
      "tensor([1, 4, 0, 3, 2])\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(sample_solution(torch.ones(5)/5))\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b09fcba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.0553, -1.5910, -1.1634, -1.9179, -1.5660])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e38f1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1281, 0.2037, 0.3124, 0.1469, 0.2089])\n",
      "tensor([0.0090, 0.0916, 0.7776, 0.0179, 0.1039])\n"
     ]
    }
   ],
   "source": [
    "softmax = torch.nn.Softmax(dim=0)\n",
    "print(softmax(t))\n",
    "print(softmax(t5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80e39a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3) tensor(-1.5452) tensor(3) tensor(-1.7250)\n",
      "tensor(0) tensor(-1.3677) tensor(0) tensor(-0.8379)\n",
      "tensor(3) tensor(-1.5452) tensor(3) tensor(-1.7250)\n",
      "tensor(4) tensor(-1.4190) tensor(4) tensor(-1.0942)\n",
      "tensor(1) tensor(-2.0031) tensor(0) tensor(-0.8379)\n",
      "tensor(0) tensor(-1.3677) tensor(3) tensor(-1.7250)\n",
      "tensor(0) tensor(-1.3677) tensor(0) tensor(-0.8379)\n",
      "tensor(0) tensor(-1.3677) tensor(4) tensor(-1.0942)\n",
      "tensor(4) tensor(-1.4190) tensor(0) tensor(-0.8379)\n",
      "tensor(0) tensor(-1.3677) tensor(4) tensor(-1.0942)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    sample = dt.sample()\n",
    "    sample5 = dt5.sample()\n",
    "    print(sample, dt.log_prob(sample), sample5, dt5.log_prob(sample5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9ab9bccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 76, 369])\n",
      "3 3\n",
      "3 5\n",
      "5 7\n",
      "7 9\n",
      "9 11\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "N = torch.randint(20, 100, (1,)).item()\n",
    "M = torch.randint(20, 500, (1,)).item()\n",
    "\n",
    "t = torch.randn(1, 1, N, M)\n",
    "print(t.shape)\n",
    "\n",
    "import torch.nn as nn\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = torch.nn.functional.silu(x)\n",
    "        return x\n",
    "modules = nn.ModuleList()\n",
    "init_block = ConvBlock(in_channels=1, out_channels=3, kernel_size=(3,3), padding=\"same\")\n",
    "for i in range(5):\n",
    "    print(in_channels:=3+max(i-1, 0)*2, out_channels:=3+i*2)\n",
    "    modules.append(ConvBlock(in_channels=3+max(i-1, 0)*2, out_channels=3+i*2, kernel_size=(3+i*2,3+i*2), padding=\"same\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dbc6a24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11, 76, 369])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = init_block(t)\n",
    "for module in modules:\n",
    "    o = module(o)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "df2455b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11, 76, 369])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Softmax(dim=-1)(o).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a04f4ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 50])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "in_channels = 128\n",
    "out_channels = 64\n",
    "n = nn.Conv1d(in_channels, out_channels, 3, padding=\"same\")\n",
    "t = torch.randn(1, in_channels, 50)\n",
    "\n",
    "o = n(t)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea5de28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding, act_fn='silu'):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.act_fn = getattr(F, act_fn)\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.act_fn(x)\n",
    "        return x\n",
    "\n",
    "class TSPVectorCNNModel(nn.Module):\n",
    "    def __init__(self, hidden_channels=16, depth=5):\n",
    "        super().__init__()\n",
    "        self.init_block = ConvBlock(1, hidden_channels, kernel_size=3, padding=\"same\")\n",
    "        self.conv_modules = nn.ModuleList()\n",
    "        for i in range(depth):\n",
    "            in_channels = hidden_channels if i == 0 else hidden_channels + (i - 1) * 2\n",
    "            out_channels = hidden_channels + i * 2\n",
    "            self.conv_modules.append(ConvBlock(in_channels, out_channels, kernel_size=3, padding=\"same\"))\n",
    "        self.lin = nn.Linear(1, 3)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        '''\n",
    "        Args:\n",
    "            x: torch tensor with shape (n_particles, n_cities)\n",
    "        Returns:\n",
    "            logits: torch tensor with shape (n_particles, 3), logits for (w, c1, c2)\n",
    "        '''\n",
    "        x = x.view(1, 1, x.size(0), x.size(1))  \n",
    "        o = self.init_block(x)\n",
    "        for module in self.conv_modules:\n",
    "            o = module(o)\n",
    "        o = o.mean(dim=[1, 3], keepdim=True)  # shape: (1, 1, n_particles, 1)\n",
    "        print(o.shape)\n",
    "        print(o.squeeze(dim=-1).squeeze(dim=0).shape)\n",
    "        o = self.lin(o).squeeze()  # shape: (n_particles, 3)\n",
    "        return self.softmax(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bcf3c066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 10, 1])\n",
      "torch.Size([1, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = TSPVectorCNNModel()\n",
    "net(torch.rand(10, 20)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97340bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing FocalNetBlock with dim=16, input_resolution=[8, 32], mlp_ratio=4.0\n",
      "Initializing FocalNetBlock with dim=16, input_resolution=[8, 32], mlp_ratio=4.0\n",
      "Initializing FocalNetBlock with dim=16, input_resolution=[8, 32], mlp_ratio=4.0\n",
      "Initializing FocalNetBlock with dim=32, input_resolution=[4, 32], mlp_ratio=4.0\n",
      "Initializing FocalNetBlock with dim=32, input_resolution=[4, 32], mlp_ratio=4.0\n",
      "Initializing FocalNetBlock with dim=32, input_resolution=[4, 32], mlp_ratio=4.0\n",
      "Initializing FocalNetBlock with dim=32, input_resolution=[4, 32], mlp_ratio=4.0\n",
      "Initializing FocalNetBlock with dim=32, input_resolution=[4, 32], mlp_ratio=4.0\n",
      "Initializing FocalNetBlock with dim=32, input_resolution=[4, 32], mlp_ratio=4.0\n",
      "Initializing FocalNetBlock with dim=64, input_resolution=[2, 32], mlp_ratio=4.0\n",
      "Initializing FocalNetBlock with dim=64, input_resolution=[2, 32], mlp_ratio=4.0\n",
      "Initializing FocalNetBlock with dim=64, input_resolution=[2, 32], mlp_ratio=4.0\n",
      "x shape after patch embed: torch.Size([1, 64, 16])\n",
      "x shape after focal layers: torch.Size([1, 64, 16])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given normalized_shape=[32], expected input with shape [*, 32], but got input of size[1, 64, 16]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m m = FocalSVTR(embed_dim=\u001b[32m16\u001b[39m)\n\u001b[32m      5\u001b[39m i = torch.randn(\u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m128\u001b[39m, \u001b[32m8\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m o = \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m o.shape\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1767\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1765\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1766\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1767\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1778\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1776\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1777\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1778\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1780\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1781\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/parzival/projects/deeppso/nets/focalsvtr.py:699\u001b[39m, in \u001b[36mFocalSVTR.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    697\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mx shape after patch embed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m--> \u001b[39m\u001b[32m699\u001b[39m     x, H, W = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    700\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mx shape after focal layers: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    704\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.feat2d:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1767\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1765\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1766\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1767\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1778\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1776\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1777\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1778\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1780\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1781\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/parzival/projects/deeppso/nets/focalsvtr.py:429\u001b[39m, in \u001b[36mBasicLayer.forward\u001b[39m\u001b[34m(self, x, H, W)\u001b[39m\n\u001b[32m    427\u001b[39m         x = checkpoint.checkpoint(blk, x)\n\u001b[32m    428\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m429\u001b[39m         x = \u001b[43mblk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.downsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    432\u001b[39m     x = x.transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m).reshape(x.shape[\u001b[32m0\u001b[39m], -\u001b[32m1\u001b[39m, H, W)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1767\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1765\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1766\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1767\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1778\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1776\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1777\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1778\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1780\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1781\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/parzival/projects/deeppso/nets/focalsvtr.py:307\u001b[39m, in \u001b[36mFocalNetBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    304\u001b[39m shortcut = x\n\u001b[32m    306\u001b[39m \u001b[38;5;66;03m# Focal Modulation\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m x = x \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_postln \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    308\u001b[39m x = x.view(B, H, W, C)\n\u001b[32m    309\u001b[39m x = \u001b[38;5;28mself\u001b[39m.modulation(x).view(B, H * W, C)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1767\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1765\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1766\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1767\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1778\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1776\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1777\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1778\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1780\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1781\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:217\u001b[39m, in \u001b[36mLayerNorm.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meps\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:2919\u001b[39m, in \u001b[36mlayer_norm\u001b[39m\u001b[34m(input, normalized_shape, weight, bias, eps)\u001b[39m\n\u001b[32m   2909\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[32m   2910\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m   2911\u001b[39m         layer_norm,\n\u001b[32m   2912\u001b[39m         (\u001b[38;5;28minput\u001b[39m, weight, bias),\n\u001b[32m   (...)\u001b[39m\u001b[32m   2917\u001b[39m         eps=eps,\n\u001b[32m   2918\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2919\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2920\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackends\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcudnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43menabled\u001b[49m\n\u001b[32m   2921\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Given normalized_shape=[32], expected input with shape [*, 32], but got input of size[1, 64, 16]"
     ]
    }
   ],
   "source": [
    "from nets.focalsvtr import FocalSVTR\n",
    "import torch\n",
    "\n",
    "m = FocalSVTR(embed_dim=16)\n",
    "i = torch.randn(1, 3, 128, 8)\n",
    "\n",
    "o = m(i)\n",
    "o.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45419ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 64, 8])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "m = nn.Conv2d(3, 16, kernel_size=[2, 1], stride=[2, 1])\n",
    "i = torch.randn(1, 3, 128, 8)\n",
    "o = m(i)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02c80023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 128])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.Conv1d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "i = torch.randn(1, 3, 128)\n",
    "o = m(i)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff3df333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 64])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.AvgPool1d(kernel_size=2)(o).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b8f2233",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1dBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding, act_fn='silu'):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size, padding=padding)\n",
    "        self.bn = nn.BatchNorm1d(out_channels)\n",
    "        self.act_fn = getattr(F, act_fn)\n",
    "    def forward(self, x, last=False):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        if not last:\n",
    "            x = self.act_fn(x)\n",
    "        return x\n",
    "\n",
    "class TSPVectorCNN1DModel(nn.Module):\n",
    "    def __init__(self, n_particles=128, emb_dim=32, act_fn='silu'):\n",
    "        super().__init__()\n",
    "        self.n_particles = n_particles\n",
    "        self.avgpool = nn.AvgPool1d(kernel_size=2)\n",
    "        self.conv1 = Conv1dBlock(n_particles, n_particles//2, kernel_size=3, padding=1, act_fn=act_fn)\n",
    "        self.conv2 = Conv1dBlock(n_particles//2, n_particles*2, kernel_size=3, padding=1, act_fn=act_fn)\n",
    "        self.conv3 = Conv1dBlock(n_particles*2, n_particles, kernel_size=3, padding=1, act_fn=act_fn)\n",
    "        self.avg_global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(1, emb_dim)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        '''\n",
    "        Args:\n",
    "            x: torch tensor with shape (n_particles, n_cities)\n",
    "        Returns:\n",
    "            logits: torch tensor with shape (n_particles, 3), logits for (w, c1, c2)\n",
    "        '''\n",
    "        x = x.view(1, x.size(0), x.size(1))  # shape: (1, n_particles, n_cities)\n",
    "        o = self.avgpool(self.conv1(x))\n",
    "        o = self.avgpool(self.conv2(o))\n",
    "        o = self.conv3(o)\n",
    "        o = self.avg_global_pool(o)\n",
    "        return self.fc(o).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9a7c2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "t = torch.randn(128, 50)\n",
    "\n",
    "net = TSPVectorCNN1DModel(n_particles=128)\n",
    "o = net(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "867f8e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 50])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.BatchNorm1d(50)\n",
    "o = net(t)\n",
    "o.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
